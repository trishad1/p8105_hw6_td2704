---
title: "P8105 Homework 6 [td2704]"
output: github_document
---


```{r, echo=FALSE, message=FALSE}

library(tidyverse)
library(dplyr)
library(modelr)
library(mgcv)

```

## Problem 1

```{r}

birthweight_df = read_csv('data/birthweight.csv')

birthweight_data = 
  birthweight_df %>%
  janitor::clean_names()  %>%
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", 
                       "asian" = "3", "puerto_rican" = "4",
                       "other" = "8"), # "unknown" = "9"
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", 
                       "asian" = "3", "puerto_rican" = "4"), # "other" = "8"
    # malform = as.factor(malform),
    # malform = fct_recode(malform, "absent" = "0", "present" = "1")
    malform = as.logical(malform)
  )

birthweight_data

```

Above, birthweight_data is a cleaned version of the original data with columns babysex, frace,  and mrace turned into factors and column malform turned into a logical ("absent" = "0"/FALSE, "present" = "1"/TRUE).


```{r}

colnames(birthweight_data)[colSums(is.na(birthweight_data)) > 0] 

```

This line above shows that none of the columns have missing values.

Propose a regression model for birthweight. 

My hypothesized structure for the factors that underly birthweight: \
babysex - difference in average birthweight by sex, \
blength - larger length = larger birthweight, \
fincome - higher income = healthier food = larger birthweight, \
malform - weight-related malformations, \
wtgain - mother's weight gain could be correlated, \
gaweeks - gestational age could be correlated

So my linear model will take into account these factors as individual variables to see which variables have the highest correlation.

```{r}
fit = lm(bwt ~ babysex + blength + fincome + malform + wtgain + gaweeks, data = birthweight_data)

fit %>% 
  broom::tidy()

```

Show a plot of model residuals against fitted values â€“ use add_predictions and add_residuals in making this plot.

```{r}

birthweight_data %>%
  modelr::add_predictions(fit) %>%
  modelr::add_residuals(fit) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  ggtitle("Model residuals vs fitted values of birthweight")

```

Let's compare the above model to the following: \
(1) One using length at birth and gestational age as predictors (main effects only). \
(2) One using head circumference, length, sex, and all interactions (including the three-way interaction) between these.

Create cross validation pairs dataframes.

```{r}

cv_df =
  crossv_mc(birthweight_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

```

Now, we fit to train data and get prediction errors (RMSE) for the test data.

```{r}

cv_df = 
  cv_df %>% 
  mutate(
    my_mod = map(train, ~lm(bwt ~ babysex + blength + fincome + malform + wtgain + gaweeks, data = .x)),
    suggested_mod1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    suggested_mod2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_suggested1 = map2_dbl(suggested_mod1, test, ~rmse(model = .x, data = .y)),
    rmse_suggested2 = map2_dbl(suggested_mod2, test, ~rmse(model = .x, data = .y)))

```

Now we plot RMSE prediction errors across all 3 models to compare.

```{r}

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  ggtitle("RMSE Prediction Errors vs Model")

```

The above plot shows RMSE prediction errors on the test data for each of the three models: \
"my" = babysex, blength, fincome, malform, wtgain, gaweeks (my hypothesized model, main effects only) \
"suggested1" = length at birth and gestational age as predictors (main effects only) \
"suggested2" = head circumference, length, sex, and all interactions (including the three-way interaction) between these

As we can see from the plot above, the second suggested model with all interactions of head circumference, length, and sex had the lowest prediction error. My hypothesized model has slightly lower error than the first suggested model, but the second suggested model seems to be the best model among the three for predicting birthweight.


## Problem 2

First load the data.

```{r}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_df

```

Write the boot_sample function to randomly sample with replacement as done in class.

```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```

Apply this function to weather_df for 5000 samples.

```{r}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps

```

Get estimates for BO (intercept), B1 (tmin coefficient), and R.squared.

```{r}

bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

bootstrap_results = 
  bootstrap_results %>% 
  select(strap_number, term, estimate) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>%
  rename("B0" = "(Intercept)") %>%
  rename("B1" = "tmin") %>%
  mutate(
    logB0B1 = log(B0*B1,base = 10)
  )

bootstrap_results

```

```{r}

bootstrap_results2 = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

bootstrap_results2
```

Plot the distribution of your estimates, and describe these in words.

```{r}

bootstrap_results2 %>%
  ggplot(aes(x=strap_number,y=r.squared)) +
  geom_point() +
  ggtitle("R^2 estimates")

bootstrap_results2 %>%
  ggplot(aes(x=r.squared)) +
  geom_histogram() +
  ggtitle("R^2 estimates")

```

From the plots above, we can see that R^2 seems to be normally distributed around 0.91/0.915.


```{r}
bootstrap_results %>% 
  ggplot(aes(x=strap_number,y=logB0B1)) +
  geom_point() +
  ggtitle("log(B0*B1) estimates")

bootstrap_results %>% 
  ggplot(aes(x=logB0B1)) +
  geom_histogram() +
  ggtitle("log(B0*B1) estimates")
```

From the plots above, we can see that log(B0*B1) seems to be normally distributed around 0.875.


Identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval.

R.squared confidence interval:

```{r}

bootstrap_results2 %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975)) %>%
  knitr::kable()

```

log(B0*B1) confidence interval:

```{r}
bootstrap_results %>% 
  summarize(
    ci_lower = quantile(logB0B1, 0.025), 
    ci_upper = quantile(logB0B1, 0.975)) %>%
  knitr::kable()
```

